---
title: "How Heterogeneity Impacts Learning"
author: |
 | Hossein Alidaee
 | Northwestern University
format: 
  revealjs: 
    auto-animate-easing: none
    auto-animate-duration: 1
    progress: false
    #theme: solarized
    theme: [solarized, custom.scss]
editor: visual
toc: false 
toc-depth: 1
toc-title: Roadmap
backgroundcolor: "#D2D7D9"
---



# Motivation

## Information From Peers Is Oddly Effective

```{r echo=FALSE, dev.args = list(bg = 'transparent'), fig.retina=2, strip.white=TRUE, fig.asp=0.2,fig.align='left'}

library(latex2exp)
library(tidyverse)
library(ggbrace)


knitr::opts_chunk$set(
      dev = "svglite",
      fig.ext = "svg"
)
```


::: fragment
Their data is noisy, but persuasive
:::

::: incremental
- A story from the field
- Rich literature on social learning 
    - Conley and Udry (2010),  Banerjee, Chandrasekhar, Duflo, and Jackson (2013), etc... 
:::

<br/><br/>

::: fragment
**So what?**
:::

::: fragment
Information is important for adoption (Rogers, 1962; Jensen, 2010)
:::


## Low AgTech Adoption Is Slowing Growth



::: columns
::: {.column width="65%"}

```{r echo=FALSE, dev.args = list(bg = 'transparent'), fig.retina=1, strip.white=TRUE, fig.asp=1,fig.align='left'}
df <- read_csv('/users/halidaee/Dropbox/Ongoing Research/Context/HYVdata.csv')


plot <- df %>% 
  pivot_longer(adv_gdp:first_gdp, names_to='gdp',names_pattern = '(.*)_gdp') %>%
  rename('Type' = 'gdp', 'GDP' = 'value') %>%
  ggplot(aes(x=year, y=GDP, color=Type)) +
    geom_line(size=2) + 
    xlab(element_blank()) +
    ylab('Real GDP per capita') +
    annotate('text',label="Western",x=1977, y=30,size=8) +
    annotate('text',label='High HYV \n Adoption  ', x=2008, y=19,size=8) +
    annotate('text',label='Low HYV \n Adoption  ', x=2008, y=3,size=8) +
    theme(axis.line=element_line(colour = 'black'),
          plot.title = element_text(size=15,face='bold'),
          axis.text.x=element_text(size=25),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          legend.position="none",
          panel.background=element_blank(),
          #panel.border=element_blank(),
          panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),
          plot.background=element_blank(),
          axis.title.y = element_text(angle = 90, vjust=0.9,size=25)) +
    scale_colour_manual(values=c('#D99066', '#402110', '#166B8C'))
plot(plot)
```




:::


::: {.column width="35%"}
::: incremental
<font size=6>

-   $2^{\text{nd}}$ divergence via Green Revolution (Huang, 2020)

<br/>

-   Structural transformation needs adoption (Suri and Udry, 2022)

<br/>

-   Information is a key barrier (Magruder, 2018) </font>
:::
:::
:::

## Social Learning: Less Data, Same Result

::: {.fragment}
Centralized sources have more data
:::

<br/>

::: {.fragment}
And spend a lot on getting it  <br/>

- India: $1.3B on public Ag R&D (IFPRI ASTI, 2022)
- 2014 Maputo Declaration: 10% of total national spending
:::



::: {.fragment}
Yet, we don't trust them much more than peers. <br/>

-  Krishnan and Patnam (2013)
-  Qiao, Friedman, Tam, Zeng and Li (2020)
:::


::: {.fragment}
**Why?**
:::

::: {.notes}
Total India Ag R&D: $4.2 Billion (IFPRI ASTI)  <br/>


:::



## Existing Explanations Are Unsatisfactory

::: fragment
Mistrust is amorphous:
:::

::: fragment
-   Exaggeration?
:::

::: fragment
-   Obfuscation?
:::

<br/><br/>

::: fragment
Homophily can't explain all:
:::

::: fragment
-   Translation is possible!
:::




## Today: Uncertainty About Heterogeneity

::: fragment

Standard view of these signals:
```{r echo=FALSE, dev.args = list(bg = 'transparent'), fig.align='center'}
#| layout-ncol: 2
#| fig-height: 5
#| fig-align: "center"


par(mar = c(0, 0, 0, 0))
certainty_text <- TeX("$Pr(k_i) = 1$")
#certainty_text <- "hello"
par(mar = c(0, 0, 0, 0))

ggplot(data = data.frame(x1 = 0, y1 = 0), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 2.5)) + 
  #geom_text(label=c(certainty_text), nudge_y=0.7) + 
  theme_minimal() + 
  labs(x = TeX("$\\theta$"),
       y = TeX("$Pr(\\theta)$")) + 
  xlim(-10, 10) + 
  ylim(0, 0.8) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=25,face='bold', hjust=0.5),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      #panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),
      axis.title.y = element_text(angle = 0, vjust=0.9),
      text = element_text(size=25)) +
      ggtitle("Peer")


ggplot(data = data.frame(x1 = 0, y1 = 0), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 0.7)) + 
  #geom_text(label=c(certainty_text), nudge_y=0.7) + 
  theme_minimal() + 
  labs(x = TeX("$\\theta$"),
       y = TeX(" $\\phantom{Pr(\\theta_i\\gamma)}$ ")) + 
  xlim(-10, 10) + 
  ylim(0, 0.8) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=25,face='bold', hjust=0.5),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      #panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),
      axis.title.y = element_text(angle = 0, vjust=0.9),
      text = element_text(size=25)) +
      ggtitle("Extension Agent")

``` 
:::


::: fragment 
Proposed view:
```{r echo=FALSE, dev.args = list(bg = 'transparent')}
#| layout-ncol: 2
#| fig-height: 5

ggplot(data = data.frame(x1 = 0, y1 = 0), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 2.5)) + 
  #geom_text(label=c(certainty_text), nudge_y=0.7) + 
  theme_minimal() + 
  labs(x = TeX("$\\theta_i$"),
       y = TeX("$Pr(\\theta_i)$")) + 
  xlim(-10, 10) + 
  ylim(0, 0.8) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=15,face='bold'),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      #panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),
      axis.title.y = element_text(angle = 0, vjust=0.9),
      text = element_text(size=25))


ggplot(data = data.frame(x1 = 0, y1 = 0), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = -6, sd = 0.7)) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = -3, sd = 0.7)) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 0.7)) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 3, sd = 0.7)) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = 6, sd = 0.7)) + 
  #geom_text(label=c(certainty_text), nudge_y=0.7) + 
  theme_minimal() + 
  labs(x = TeX("$\\theta_i$"),
       y = TeX("$Pr(\\theta_i|\\gamma_k)$")) + 
  xlim(-10, 10) + 
  ylim(0, 0.8) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=15,face='bold'),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      #panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),
      axis.title.y = element_text(angle = 0, vjust=0.9),
      text = element_text(size=25)) 

```

:::


## Related Literature
<font size = 5>

- Decision makers as statisticians
  - asdf
- Social learning theory
  - asdf
- Information interventions
  - asdf
- Role of heterogeneity in agents' responses to information
  - asdf
- Role of trust in agents' responses to information
  - asdf
- Frictions in agricultural technology adoption
  - asdf
- Agricultural extension design
  - asdf

</font>

## Roadmap

::: incremental
Today:

-   Overview of agricultural extension
-   Propose a foundation for mechanism
-   Explain the difficulty testing in the field
-   Design a lab-in-the-field experiment
-   Present results
-   Implications for farmers and policymakers
:::


<!--# Heterogeneous Returns to Technology         Returns are often heterogeneous:     Education - comparative advantage (Heckman and Li, 2004), gender (Dougherty, 2005)   Microfinance - credit constraints (Banerjee et al, 2020), business experience (Meager, 2019) Skills training - baseline profits (Lopez-Pena, 2020)   Health - age (Dupas, 2009)   Whose data do I trust? -->

# Overviewing Agricultural Extension



## Traditional Extension Design Is Centralized

::: incremental
-   Big % of govermment ag budget  (Akroyd and Smith, 2007)

-   Centralized testing of technologies

-   Centralized training of extension agents

-   Extension agents relay knowledge to farmers
:::

## We Know What Works Better


::: fragment
<font size="6px">

-   Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019)

-   Farmer Field Days (Dar and Emerick, 2021)

-   Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020)

-   Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)

-   Opinion Leader Superiority (Feder and Savastano, 2006)

-   Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020)

-   Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017)

-   ICT Reduction of Temporal Lag (Cole and Fernando, 2021)

-   Many more!

</font>
:::

## It's Unclear We Know Why

::: fragment
Some potential mechanisms:
:::

::: incremental

- Sample size
- Centrality
- Social influence
- Homophily
:::

::: fragment
**None are broadly consistent with the literature**
:::

:::incremental
- Program design more effective when mechanism is known
- RCTs have difficulty isolating mechanisms
:::

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | | | | | |
|  Field Days| | | | | |
|Season-long Demonstration Plots| | | | | |
| Seed Centrality| | | | | |
| Opinion Leader Superiority| | | | | |
| Demonstration Plot Centrality| | | | | |
| Direct Contact Farmer Training| | | | | |
| ICT to Reduce Temporal Lag| | | | | |

</font>

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | &cross;| | | | |
|  Field Days| | | | | |
|Season-long Demonstration Plots| | | | | |
| Seed Centrality| | | | | |
| Opinion Leader Superiority| | | | | |
| Demonstration Plot Centrality| | | | | |
| Direct Contact Farmer Training| | | | | |
| ICT to Reduce Temporal Lag| | | | | |





</font>

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | &cross;| | | | |
|  Field Days| | | | | |
|Season-long Demonstration Plots| | | | | |
| Seed Centrality| | &check; | | | |
| Opinion Leader Superiority| | | | | |
| Demonstration Plot Centrality| | &cross; | | | |
| Direct Contact Farmer Training| | | | | |
| ICT to Reduce Temporal Lag| | | | | |

</font>

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context  |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | &cross;| | | | |
|  Field Days| | | &cross; | | |
|Season-long Demonstration Plots| | | | | |
| Seed Centrality| | &check; | &check; | | |
| Opinion Leader Superiority| | | &cross; | | |
| Demonstration Plot Centrality| | &cross; | &cross;| | |
| Direct Contact Farmer Training| | | | | |
| ICT to Reduce Temporal Lag| | | | | |


</font>

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context  |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | &cross;| | | &check; | |
|  Field Days| | | &cross; | | |
|Season-long Demonstration Plots| | | | | |
| Seed Centrality| | &check; | &check; | &cross; | |
| Opinion Leader Superiority| | | &cross; | &check; | |
| Demonstration Plot Centrality| | &cross; | &cross;| | |
| Direct Contact Farmer Training| | | | | |
| ICT to Reduce Temporal Lag| | | | | |


</font>

## What works and why?

<font size="5">

| | Sample Size | Centrality | Social Power | Homophily | Context  |
| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
| Decentralized Learning | &cross;| | | &check; | &check;|
|  Field Days| | | &cross; | | &check;|
|Season-long Demonstration Plots| | | | | &check;|
| Seed Centrality| | &check; | &check; | &cross; | &check;|
| Opinion Leader Superiority| | | &cross; | &check; | &check;|
| Demonstration Plot Centrality| | &cross; | &cross;| |&check; |
| Direct Contact Farmer Training| | | | | &check;|
| ICT to Reduce Temporal Lag| | | | | &check; |


</font>


<!-- 
<font size="5">

-   Decentralized Learning 

-   <font style="opacity:.6"> Farmer Field Days  </font>

-   <font style="opacity:.6"> Season-long Demonstration Plots  </font>

-   <font style="opacity:.6">Seed Centrality  </font>

-   <font style="opacity:.6">Opinion Leader Superiority  </font>

-   <font style="opacity:.6"> Demonstration Plot Centrality  </font>

-   <font style="opacity:.6"> Direct Contact Farmer Training  </font>

-   <font style="opacity:.6"> ICT Reduction of Temporal Lag  </font>

</font> 

## What works and why?

Does **centrality** drive learning?

<font size="5">

-   <font style="opacity:.6">Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019) </font>

-   <font style="opacity:.6"> Farmer Field Days (Dar and Emerick, 2021) </font>

-   <font style="opacity:.6"> Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020) </font>

-   **Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)**

-   <font style="opacity:.6"> Opinion Leader Superiority (Feder and Savastano, 2006) </font>

-   ~~Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020)~~

-   <font style="opacity:.6"> Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017) </font>

-   <font style="opacity:.6"> ICT Reduction of Temporal Lag (Cole and Fernando, 2021) </font>

</font>

## What works and why?

Does **social influence** drive learning?

<font size="5">

-   <font style="opacity:.6">Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019) </font>

-   ~~Farmer Field Days (Dar and Emerick, 2021)~~

-   <font style="opacity:.6"> Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020) </font>

-   **Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)**

-   ~~Opinion Leader Superiority (Feder and Savastano, 2006)~~

-   ~~Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020)~~

-   <font style="opacity:.6"> Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017) </font>

-   <font style="opacity:.6"> ICT Reduction of Temporal Lag (Cole and Fernando, 2021) </font>

</font>

## What works and why?

Does **homophily** drive learning?

<font size="5">

-   **Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019)**

-   <font style="opacity:.6"> Farmer Field Days (Dar and Emerick, 2021) </font>

-   <font style="opacity:.6"> Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020) </font>

-   ~~Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)~~

-   **Opinion Leader Superiority (Feder and Savastano, 2006)**

-   <font style="opacity:.6"> Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020) </font>

-   <font style="opacity:.6"> Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017) </font>

-   <font style="opacity:.6"> ICT Reduction of Temporal Lag (Cole and Fernando, 2021) </font>

</font>

## What works and why?

Does **knowledge about context** drive learning?

<font size="5">

-   **Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019)**

-   **Farmer Field Days (Dar and Emerick, 2021)**

-   **Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020)**

-   **Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)**

-   **Opinion Leader Superiority (Feder and Savastano, 2006)**

-   **Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020)**

-   **Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017)**

-   **ICT Reduction of Temporal Lag (Cole and Fernando, 2021)**

</font> -->


## Recap

::: incremental
- Growth requires higher agtech adoption
- Traditional extension design is centralized
- Many RCTs improving extension design
- Mechanisms aren't yet well identified
- Context certainty explains a broad set of results
:::


# Context Uncertainty As A Mechanism

## Technology returns are often heterogeneous

::: incremental
-   **Education** 
    - Comparative advantage (Heckman and Li, 2004)
    - Gender (Dougherty, 2005)

-   **Microfinance** 
    * Credit constraints (Banerjee et al, 2020)
    * Business experience (Meager, 2019)

-   **Skills training** 
    - Baseline profits (Lopez-Pena, 2020)

-   **Health** 
    - Age (Dupas, 2009)
:::

## Signals With Certain versus Uncertain Context

:::  fragment
For some signals, we don't know the context:
:::

::: incremental
-   Random online reviews
-   Government plot's soil content
-   Sample for stated returns to education
:::

::: fragment
Other times, we do:
:::

::: incremental
-   Friend's preference for goods
-   Neighboring farmer's soil
-   Peer's access to job opportunities
:::


## Context Reduces Risk

::: {.fragment .fade-in}
```{r echo=FALSE, dev.args = list(bg = 'transparent'), fig.retina=2, strip.white=TRUE, fig.asp=0.35,fig.align='left'}

colors <- rep('#D99066', 7)
x_vals <- seq(-6, 6, 2)
ggplot(data = data.frame(x1 = x_vals, y1 = c(0,0,0,0,0,0,0)), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[1], sd = 0.4), colour = colors[1]) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[2], sd = 0.4), colour = colors[2]) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[3], sd = 0.4), colour = colors[3]) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[4], sd = 0.4), colour = colors[4]) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[5], sd = 0.4), colour = colors[5]) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[6], sd = 0.4), colour = colors[6]) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[7], sd = 0.4), colour = colors[7]) +
  #stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 3), colour = '#166B8C') + 
  #geom_text(aes(y=type_label_heights), label=type_labels) + 
  theme_minimal() + 
  geom_brace(aes(x=c(-7,7), y=c(1, 1.1)),inherit.data=F, inherit.aes=F) +
  geom_text(aes(x=0, y=1.13), label=TeX("$Pr(k_j) = 0.14 \\ \\forall \\ j$")) +
  #geom_curve(aes(x = 8, y= 0.4, xend=0, yend=0.2),arrow=arrow(length=unit(0.03,"npc"))) +
  #geom_text(aes(x=8.5, y=0.35), label=TeX("$Pr(k_i) = 1$")) + 
  labs(x = TeX("$U(f(s_i))$"),
       y = TeX("$Pr(s_i | k_i)$")) + 
  xlim(-10, 10) + 
  ylim(0, 1.2) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=15,face='bold'),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        legend.position="none",
        panel.background=element_blank(),
        #panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        plot.background=element_blank(),
        axis.title.y = element_text(angle = 0, vjust=0.9)) + 
  ggtitle('Uncertain Context') 

```
:::

::: {.fragment .fade-in-then-semi-out}
```{r echo=FALSE, dev.args = list(bg = 'transparent'), fig.retina=2, strip.white=TRUE, fig.asp=0.35,fig.align='left'}

colors <- rep('#D99066', 7)
x_vals <- seq(-6, 6, 2)
ggplot(data = data.frame(x1 = x_vals, y1 = c(0,0,0,0,0,0,0)), aes(x=x1, y=y1) ) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[1], sd = 0.4), colour = colors[1], alpha=0.2) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[2], sd = 0.4), colour = colors[2], alpha=0.2) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[3], sd = 0.4), colour = colors[3], alpha=0.2) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[4], sd = 0.4), colour = colors[4], alpha=0.2) + 
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[5], sd = 0.4), colour = colors[5], alpha=0.2) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[6], sd = 0.4), colour = colors[6], alpha=1) +
  stat_function(fun = dnorm, n = 1001, args = list(mean = x_vals[7], sd = 0.4), colour = colors[7], alpha=0.2) +
  #stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 3), colour = '#166B8C') + 
  #geom_text(aes(y=type_label_heights), label=type_labels) + 
  theme_minimal() + 
  geom_text(aes(x=x_vals[6], y=1.1), label=TeX("$Pr(k_6) = 1$")) +
  #geom_brace(aes(x=c(-7,7), y=c(1, 1.1)),inherit.data=F, inherit.aes=F) +
  #geom_text(aes(x=0, y=1.13), label=TeX("$Pr(k_j) = 0.14 \\ \\forall \\ j$")) +
  #geom_curve(aes(x = 8, y= 0.4, xend=0, yend=0.2),arrow=arrow(length=unit(0.03,"npc"))) +
  #geom_text(aes(x=8.5, y=0.35), label=TeX("$Pr(k_i) = 1$")) + 
  labs(x = TeX("$U(f(s_i))$"),
       y = TeX("$Pr(s_i | k_i)$")) + 
  xlim(-10, 10) + 
  ylim(0, 1.2) + 
  theme(axis.line=element_line(colour = 'black'),
        plot.title = element_text(size=15,face='bold'),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        legend.position="none",
        panel.background=element_blank(),
        #panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        plot.background=element_blank(),
        axis.title.y = element_text(angle = 0, vjust=0.9)) + 
  ggtitle('Certain Context') 
  
```
:::

## Uncertainty can be decomposed

<font size=6>
A risk averse agent is estimating $$\theta_i = \underbrace{\theta \vphantom{\gamma_i}  }_{\text{average return}} + \underbrace{\gamma_i}_{\text{context adjustment}}.$$

::: {.fragment}
They can choose among many signals $\widehat{\theta}_j = \widehat{\operatorname{E}}\left[\theta + \gamma_j\right]$.
:::

</br>

::: {.fragment}
MSE can be decomposed into three components:

```{=tex}
\begin{aligned}
 \operatorname{E}\left[(\theta_i - \widehat{\operatorname{E}}[\theta_i | s_j, \gamma_i])^2\right]    

% &= \operatorname{E}\left[\left(\theta_i - \left(\widehat{\theta}_j - \operatorname{E}[\gamma_j]  + \gamma_i\right) ]\right)^2\right] \\

&= \underbrace{\left(\operatorname{E}[\widehat{\gamma}_j] - \gamma_j\right)^2 \vphantom{\left[s\left(sdE[\gamma_j]\right)^2\right]^2}  }_{\text{Context Bias}} + \underbrace{\operatorname{E}\left[\left(\operatorname{E}[\widehat{\gamma}_j] - \widehat{\gamma}_j\right)^2\right]}_{\text{Context Variance}}  + \underbrace{\hphantom{abc}\sigma^2_j \hphantom{abc}\vphantom{\left[s\left(sdE[\gamma_j]\right)^2\right]^2}}_{\text{Est. Variance}}


\end{aligned}
```
</font>
:::

## Error from central vs social data


::: fragment
Farmers often must choose between believing: 
:::


::: incremental
 - Social data: low $N$, well known context
 - Central data: high $N$, unknown context
:::


::: fragment


```{=tex}



$$MSE(\theta_i) = \text{Context Bias} + \text{Context Variance} \\ + \text{Est. Variance} $$

```
:::


::: {.fragment}
<!-- Now insert a 2x3 markdown table where the columns are the three MSE components and the rows are the types of data sources  -->
|  | Context Bias | Context Variance | Est. Variance |
| --- | --- | --- | --- |
| Central | ? | High | Low |
| Social | ? | Low | High |
::: 




# Microfoundation

## A Stylized Model

A farmer is:

-   risk-averse
-   Bayesian
-   deciding between a traditional vs high-yield seed

::: fragment
The unknown gain from the high yield seed is heterogeneous: $$\theta_i = \underbrace{\theta \vphantom{\gamma_i}  }_{\text{average return}} + \underbrace{\gamma_i}_{\text{context adjustment}}$$
:::

## Sources of Context Heterogeneity

Why is context $\gamma_j$ heterogeneous?:

::: fragment
-   soil composition
-   labor input access
-   irrigation use
-   ...
:::

## What is known about context?

Each individual $j$ has their own $\gamma_j \sim \mathcal{N}\left(0, (\sigma_j^\gamma)^2\right).$

<br/><br/>

::: fragment
$\gamma_j$ is individual $j$'s **context**.
:::

<br/><br/>

::: fragment
$\sigma_j^\gamma$ is the **context uncertainty**.
:::

## Information Environment

<font size=6>

|                      |                   Extension Agent                   |                   Friends                    |
|:----------------|:----------------------------:|:------------------------:|
| Uninformative Prior? |                        True                         |                     True                     |
| \# of Signals        |                         $M$                         |          1 each <br> ($N$ friends)           |
| Signal Structure     | $\mathbf{s}_E = \theta_E + \boldsymbol{\epsilon}_M$ |   $s_j = \theta_j + \epsilon_j \forall j$    |
| Signal Noise         |  $\epsilon_m \sim \mathcal{N}(0, \sigma_E^2)$ iid   | $\epsilon_j \sim \mathcal{N}(0, \sigma_j^2)$ |
| Info Sharing         |          $\operatorname{E}[\mathbf{s}_E]$           |          $\mathbf{s}_j$, $\gamma_j$          |
| Common Knowledge     |        Prior, $\sigma_E$, $\sigma_E^\gamma$         |     Prior, $\sigma_j$, $\sigma_E^\gamma$     |

</font>

## Signals without Context

Imagine friend $j$ shares signal $s_j = \theta + \gamma_j + \epsilon_j$.

<br/><br/>

Without $\gamma_j$, this is a signal about $\theta_j = \theta + \gamma_j$.

## How an Agent Adjusts for Context

How does sharing context $\gamma_j$ impact learning?

<br/><br/>

Consider estimating $\theta_i$ with context uncertainty:

```{=tex}
\begin{align}

\operatorname{E}[\theta_i | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i] &= \operatorname{E}[s_j - \epsilon_j - \gamma_j + \gamma_i  | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i] \\
&= s_j + \gamma_i - \operatorname{E}[ \epsilon_j + \gamma_j | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i] \\


\end{align}
```
Knowing $\gamma_j$ allows perfect adjustment:

::: {style="margin-top:-80px;"}
```{=tex}
\begin{align}


\hphantom{\operatorname{E}[\theta_i | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i]} &\hphantom{=} \hphantom{\operatorname{E}[s_j - \epsilon_j - \gamma_j + \gamma_i  | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i]} \\

&= s_j + \underbrace{\left(\gamma_i - \gamma_j\right)}_{\text{Adjustment}} +  \operatorname{E}[ \epsilon_j | s_j, \sigma_j, \sigma_j^\gamma, \gamma_i] 


\end{align}
```
:::

## Risk Averse Agents Want Data on Context

Because the farmer is risk averse,

$$\operatorname{E}[U(\theta_i)] \leq U(\operatorname{E}[\theta_i]).$$ Thus, all else equal, he prefers taking $\gamma_j$ out of the expectation:

```{=tex}
\begin{align}

\operatorname{E}[U(s_j + \gamma_i - \epsilon_j + \gamma_j)] &\leq U\left(\operatorname{E}[s_j + \gamma_i - \epsilon_j + \gamma_j]\right) \\

&\leq U\left(s_j + (\gamma_i -\gamma_j) - \operatorname{E}[\epsilon_j ]\right)

\end{align}
```
## The Real World Has A Context - Data Tradeoff 

But what if knowing $\gamma_j$ requires adding noise?

<br/><br/>

If $U(s_j)$ is maximized by minimizing MSE, then

```{=tex}
\begin{aligned}
U(s_j) &=  \operatorname{E}\left[(\theta_i - \widehat{\operatorname{E}}[\theta_i | s_j, \gamma_i])^2\right]    \\


&= \underbrace{\left(\operatorname{E}[\widehat{\gamma}_j] - \gamma_j\right)^2 \vphantom{\left[s\left(sdE[\gamma_j]\right)^2\right]^2}  }_{\text{Context Bias}} + \underbrace{\operatorname{E}\left[\left(\operatorname{E}[\widehat{\gamma}_j] - \widehat{\gamma}_j\right)^2\right]}_{\text{Context Variance}}  + \underbrace{\hphantom{abc}\sigma^2_j \hphantom{abc}\vphantom{\left[s\left(sdE[\gamma_j]\right)^2\right]^2}}_{\text{Est. Variance}}


\end{aligned}
```
## Who Should A Farmer Listen To?

<br/><br/>

::: {.theorem text="Maximizing Adoption"}
Adoption will be maximized by the source minimizing total uncertainty

```{=tex}
\begin{align}

\left(\frac{M}{\sigma^2_E + (\sigma_E^\gamma)^2}\right)^{-1}  

&\text{ vs } 

\left( \sum_j \frac{1}{\sigma_j^2 + (\sigma_j^\gamma)^2 }\right)^{-1}

\end{align}
```
:::

## Traditional and Contextual Data are Complements

<br/><br/>

::: {.theorem text="Supermodular Updating"}
The value of an additional observation by the sender of the signal (i.e. observing $M + 1$ instead of $M$ farms) is increasing in context precision $\left(1/\sigma_i^\gamma\right)^2$.
:::

# Lab Experiment Design

## What do we know?

We have many field experiments!

<font size="6">

-   Decentralized Learning (Krishnan and Patnam, 2013; Takahashi, Mano, and Otsuka, 2019)

-   Farmer Field Days (Dar and Emerick, 2021)

-   Season-long Demonstration Plots (Maertens, Michelson, and Nourani, 2020)

-   Seed Centrality (Banerjee, Chandrasekhar, Duflo, and Jackson, 2013; Shikuku, 2019)

-   Opinion Leader Superiority (Feder and Savastano, 2006)

-   Demonstration Plot Centrality (Dar, Emerick, de Janvry, Kelley, and Sadoulet, 2020)

-   Direct Contact Farmer Training (Kondylis, Mueller, and Zhu, 2017)

-   ICT Reduction of Temporal Lag (Cole and Fernando, 2021)

</font>

## What's missing?

Each design has a number of confounders:

<font size=6>

-   social pressure
-   heterogeneous opportunity costs
-   correlated signals
-   correlation neglect from info sharing
-   multi-period updating
-   credit constraints
-   strategic interaction
-   informed priors
-   ...

</font>

<br/>

::: fragment
None can precisely identify a mechanism.
:::

## What's the path to scale?

<br/>

1.  Precisely identify the mechanism in the lab
2.  Adapt it to constraints in the field
3.  Revise

## Vignette Study Summary

-   Vignette experiment via tablet game
-   Brief survey on information sources
-   Odisha (Orissa), India
-   Smallholder farmers
-   Within-subject design

## Game Design

<font size=5> **Background**: Technology, Village

**Outcome**: Adoption intensity (0-10)

::: r-stack
::: {.fragment .fade-in-then-out}
**Data**: Each NPC has two features:

-   Plot type (blue vs orange)
-   Satisfaction (1-7)
-   Plot visibility (colored vs gray)
:::

::: {.fragment .fade-in}
![](game_5.png){fig-align="center" width="500"}
:::
:::

**Your Info**:

-   You plot is orange type.
-   Blue to orange conversion

</font>

<!-- ## Histogram View

Users have the choice of two views:

::: panel-tabset
### Map View

![](complex_map_1.png){fig-align="center" width="500"}

### Histogram View

![](complex_histogram_1.png){fig-align="center" width="700"}
::: -->


## Experimental Variation

::: columns
::: {.column width="35%"}
<font size=5>

**Within Variation**:

-   \% of Gray Tiles

<br/>

**Across Variation**:

-   Round Order
-   Village, Tech

<br/>

**Constant**:

-   Blue/Orange Ratio
-   Signal distribution

</font>
:::

::: {.column width="65%"}
![](game_5.png){fig-align="center" width="500"}

![](game_13.png){fig-align="center" width="500"}
:::
:::

## Estimation

```{=tex}
\begin{align}

\text{Adoption Level}_{ij}=\beta_H \mathbb{1}(\text{High Type Uncertainty}) + \\
\beta_G \text{Game Controls} + \beta_D \text{Demographic Controls}

\end{align}
```
::: columns
::: {.column width="50%"}
**Game Controls**:

-   Round Number
-   Technology
-   Village
:::

::: {.column width="50%"}
**Demographic Controls**:

-   Age
-   Household Size
-   Income
-   Education
-   Game Behavior
:::
:::

## Testing Complementarity

::: {.theorem text="Supermodular Updating"}
The value of an additional observation by the sender of the signal (i.e. observing $M + 1$ instead of $M$ farms) is increasing in context precision $\left(1/\sigma_i^\gamma\right)^2$.
:::

![](DiffInDiffTable.png){fig-align="center" width="600"}

## Control Modules

**Additional modules for**:

-   Practice rounds
-   Ability to translate across types
-   Bounding heuristic behavior

## Structural Estimation

Using the diff-in-diff design, we can structurally estimate risk aversion.

<br/>

Assume CARA utility: $u(\theta_i) = 1 - e^{-a\theta_i}$

<br/>

Klibanoff et al. (2005) allows testing $$a_C \lesseqqgtr a_S$$

# Field Experiment Design

## Disaggregating Mincerian Earnings

You're deciding whether to enroll your daughter in school for an extra year. I expose you to one of three main treatment arms:

-   I show you returns to this year of education for a random person
-   I show you returns for individuals similar to your daughter in terms of grades
-   I show you returns for individuals with worse grades

# Conclusion

## Potential Implications

Potential lessons:

-   Info campaigns should provide specific returns
-   Information campaigns should disaggregate returns
-   Distributed, local experimentation could increase trust
-   Insurance with low basis-risk, when tied to experimentation, can have high positive externalities
-   Reinforces Oates (1972, 1999) argument in favor of decentralization

## Future area of study

-   Barriers to signal translation
-   Specific vs disaggregated signals

# Thank You
